version: '3'
services:
  hadoop-spark:
    image: danieltaipei731/docker-hadoop-spark:v2
    hostname: master
    container_name: master
    restart: always
    stdin_open : true
    tty: true
    command: > 
      bash -c "/etc/init.d/ssh start
      && cd /home/hadoop-2.10.0/sbin/
      && ./start-dfs.sh
      && cd /home/spark-2.4.5-bin-hadoop2.7/sbin/
      && ./start-all.sh
      && tail -f /dev/null"
    ports:
      - "50070:50070"
      - "8080:8080"
    volumes:
      - ./hs_code:/home/code/
      - ./hdfs/namenode:/home/hdfs/namenode
      - ./hdfs/datanode:/home/hdfs/datanode

  jupyter:
    build:
      context: ./dockerfile
      dockerfile: dockerfile-jupyter
    container_name: chatbot_jupyter
    tty: true
    stdin_open: true
    depends_on:
      - db 
    ports:
      - "5000:5000"
      - "8888:8888"
    command: start-notebook.sh --NotebookApp.token=''
    volumes:
      - ./code:/home/jovyan/work
  
  db:
    image: mysql
    container_name: chatbot_db
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=123456
    volumes:
      - ./mysql_data:/var/lib/mysql

  ngrok:
    image: wernight/ngrok
    container_name: chatbot_ngrok
    tty: true
    stdin_open: true
    ports:
      - "4040"
    depends_on:
      - jupyter
    command: ngrok http chatbot_jupyter:5000 
